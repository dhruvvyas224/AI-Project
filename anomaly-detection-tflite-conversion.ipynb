{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Lite Conversion\n",
    "---\n",
    "Convert the full Keras model into a smaller TensorFlow Lite model file. Then, read in the raw hex bytes from the model file and write them to a separate C header file as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from scipy import stats\n",
    "import c_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.7\n",
      "Numpy 1.23.4\n",
      "TensorFlow 2.12.0\n",
      "Keras 2.12.0\n"
     ]
    }
   ],
   "source": [
    "# Print versions\n",
    "!python --version\n",
    "print('Numpy ' + np.__version__)\n",
    "print('TensorFlow ' + tf.__version__)\n",
    "print('Keras ' + tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "models_path = 'D:\\ML\\ML Project\\Try\\Auto-Encoder\\Models'  # Where we can find the model files (relative path location)\n",
    "keras_model_name = 'New_Model'           # Will be given .h5 suffix\n",
    "tflite_model_name = 'keras_model_deploy'          # Will be given .tflite suffix\n",
    "c_model_name = 'keras_model_deploy'               # Will be given .h suffix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = models.load_model(join(models_path, keras_model_name) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\wwwdh\\AppData\\Local\\Temp\\tmph70wm1az\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\wwwdh\\AppData\\Local\\Temp\\tmph70wm1az\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1560"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(join(models_path, tflite_model_name) + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct header file\n",
    "hex_array = [format(val, '#04x') for val in tflite_model]\n",
    "c_model = c_writer.create_array(np.array(hex_array), 'unsigned char', c_model_name)\n",
    "header_str = c_writer.create_header(c_model, c_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save C header file\n",
    "with open(join(models_path, c_model_name) + '.h', 'w') as file:\n",
    "    file.write(header_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Inference\n",
    "---\n",
    "Get known good values from the model for normal and anomaly samples to compare against C++ implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved Numpy test samples file location\n",
    "sample_file_path = '..\\\\test_samples'\n",
    "sample_file_name = 'normal_anomaly_samples'  # Will be given .npz suffix\n",
    "\n",
    "sensor_sample_rate = 200    # Hz\n",
    "sample_time = 0.64           # Time (sec) length of each sample\n",
    "max_measurements = int(sample_time * sensor_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "(200, 3)\n",
      "[[0.07666  0.170898 0.981445]\n",
      " [0.063477 0.169434 0.988281]\n",
      " [0.073242 0.166992 0.989258]\n",
      " [0.07373  0.170898 0.987305]\n",
      " [0.069336 0.166992 0.989746]]\n"
     ]
    }
   ],
   "source": [
    "# Load test samples\n",
    "with np.load(join(sample_file_path, sample_file_name) + '.npz') as data:\n",
    "    normal_sample = data['normal_sample']\n",
    "    anomaly_sample = data['anomaly_sample']\n",
    "print(normal_sample.shape)\n",
    "print(anomaly_sample.shape)\n",
    "print(normal_sample[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal MAD: [0.00615279 0.00217201 0.00398226]\n",
      "Anomaly MAD: [0.00579178 0.00506753 0.00542928]\n"
     ]
    }
   ],
   "source": [
    "# Test extracting features (median absolute deviation) using SciPy\n",
    "sample = normal_sample[0:max_measurements]                  # Truncate to 128 measurements\n",
    "normal_x = stats.median_absolute_deviation(sample)  # Calculate MAD\n",
    "sample = anomaly_sample[0:max_measurements]\n",
    "anomaly_x = stats.median_absolute_deviation(sample)\n",
    "print(\"Normal MAD:\", normal_x)\n",
    "print(\"Anomaly MAD:\", anomaly_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.00738949 0.         0.00136751]]\n",
      "MSE: 4.361337928178523e-06\n"
     ]
    }
   ],
   "source": [
    "# Perform inference and find MSE with normal sample\n",
    "input_tensor = normal_x.reshape(1, -1)\n",
    "pred = model.predict(input_tensor)\n",
    "mse = np.mean(np.power(normal_x - pred, 2), axis=1)\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"MSE:\", *mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.00756477 0.         0.00288103]]\n",
      "MSE: 1.1772313892536478e-05\n"
     ]
    }
   ],
   "source": [
    "# Perform inference and find MSE with anomaly sample\n",
    "input_tensor = anomaly_x.reshape(1, -1)\n",
    "pred = model.predict(input_tensor)\n",
    "mse = np.mean(np.power(anomaly_x - pred, 2), axis=1)\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"MSE:\", *mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
